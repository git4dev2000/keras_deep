#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Sep  5 12:07:43 2018

@author: mansour
"""
import numpy as np
from keras.datasets import reuters
from keras import models
from keras.layers import Dense
from keras import optimizers
from keras import losses
from keras import metrics
from keras.utils import to_categorical
from matplotlib import pyplot as plt


(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000)

def input_2_tensor(x, n_col=10000):
    res = np.zeros(shape=(len(x), n_col))
    for idx, elm in enumerate(x):
        res[idx,elm] = 1.
    return res

x_train, x_test = [input_2_tensor(elm) for elm in (x_train, x_test)]
y_train, y_test = [to_categorical(elm.astype("float32")) for elm in (y_train, y_test)]


x_val, y_val = [elm[:1000] for elm in (x_train, y_train)]
x_train_sub, y_train_sub = [elm[1000:] for elm in (x_train, y_train)]

nn_model = models.Sequential()
nn_model.add(layer=Dense(units=64, activation='relu', input_shape = (10000,)))
nn_model.add(layer=Dense(units=64, activation='relu'))
nn_model.add(layer=Dense(units=46, activation='softmax'))

nn_model.compile(optimizer=optimizers.RMSprop(lr=0.001),
                 loss=losses.categorical_crossentropy,
                 metrics=[metrics.categorical_accuracy])

history = nn_model.fit(x=x_train_sub, y=y_train_sub,
             batch_size=512, epochs=20,
             validation_data=(x_val,y_val))

history_dict = history.history

epoches = range(1,len(history_dict.get('loss'))+1)
plt.plot(epoches, history_dict.get('loss'),'bo',label="Loss")
plt.plot(epoches, history_dict.get('val_loss'),'b',label="Validation_Loss")
plt.xlabel = "Epoches"
plt.ylabel = "Loss"
plt.legend()
plt.show()

# Getting the minimum validation losss
val_loss = history_dict.get('val_loss')
best_epoch = val_loss.index(min(val_loss)) + 1

# Retraining using optimum epoch number and making predictions...
nn_model = models.Sequential()
nn_model.add(layer=Dense(units=64, activation='relu', input_shape = (10000,)))
nn_model.add(layer=Dense(units=64, activation='relu'))
nn_model.add(layer=Dense(units=46, activation='softmax'))

nn_model.compile(optimizer=optimizers.RMSprop(lr=0.001),
                 loss=losses.categorical_crossentropy,
                 metrics=[metrics.categorical_accuracy])

history = nn_model.fit(x=x_train_sub, y=y_train_sub,
             batch_size=512, epochs=best_epoch,
             validation_data=(x_val,y_val))

# Evaluating performance...
loss, accuracy = nn_model.evaluate(x=x_test, y=y_test)

# Making predictions using trained network...
pred = nn_model.predict(x=x_test)









